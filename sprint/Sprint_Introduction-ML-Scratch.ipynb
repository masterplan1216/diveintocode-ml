{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **機械学習スクラッチ入門**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。\n",
    "\n",
    "このSprintでは機械学習手法のスクラッチ課題に取り組む準備を行います。scikit-learnを用いて分類・回帰問題を解くコードを書いておき、今後のSprintではそれと同じ動作をするクラスをスクラッチで作成していきます。\n",
    "\n",
    "**【スクラッチの意義】**  \n",
    "ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "\n",
    "\n",
    "スクラッチをすることでscikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "以下のような効果を狙っています。\n",
    "- 新たな手法に出会った時に理論・数式を理解しやすくする\n",
    "- ライブラリを使う上での曖昧さを減らす\n",
    "- 既存の実装を読みやすくする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。  \n",
    "\n",
    ">[参考1](https://www.it-swarm.dev/ja/python/numpy%ef%bc%9a2d%e9%85%8d%e5%88%97%e3%81%8b%e3%82%89%e8%a1%8c%e3%81%ae%e3%83%a9%e3%83%b3%e3%83%80%e3%83%a0%e3%82%bb%e3%83%83%e3%83%88%e3%82%92%e5%8f%96%e5%be%97%e3%81%97%e3%81%be%e3%81%99/1069900142/)  \n",
    "[参考2](https://www.sky-limit-future.com/entry/numpy-aggregate-function)  \n",
    "[numpy.random.choice](https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.random.choice.html)  \n",
    "[numpy.setdiff1d](https://numpy.org/doc/stable/reference/generated/numpy.setdiff1d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    #Xから（Xのサンプル数*train_size）個のランダムな行をndarrayとして抜き出す\n",
    "    train_row_num = np.random.choice(X.shape[0], \\\n",
    "                                                                   size=int(Decimal(X.shape[0]*train_size).quantize(Decimal(\"0\"), rounding = ROUND_HALF_UP)), \\\n",
    "                                                                   replace=False)\n",
    "    X_train = X[train_row_num, :]\n",
    "    \n",
    "    #XとX_trainの差集合がX_test\n",
    "    test_row_num = np.setdiff1d(np.array(range(X.shape[0])), train_row_num)\n",
    "    X_test = X[test_row_num, :]\n",
    "    \n",
    "    y_train = y[train_row_num]\n",
    "    y_test = y[test_row_num]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- スクラッチした関数の整合性確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_X:\n",
      "[[12 15]\n",
      " [21  0]\n",
      " [ 3 27]\n",
      " [ 3  7]\n",
      " [ 9 19]\n",
      " [21 18]\n",
      " [ 4 23]\n",
      " [ 6 24]\n",
      " [24 12]\n",
      " [26  1]]\n",
      "ex_y:\n",
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "--------------------\n",
      "X_train:\n",
      "[[ 9 19]\n",
      " [26  1]\n",
      " [21  0]\n",
      " [ 4 23]\n",
      " [ 6 24]\n",
      " [ 3  7]\n",
      " [12 15]\n",
      " [21 18]]\n",
      "y_train:\n",
      "[0 1 0 1 1 0 0 1]\n",
      "X_test:\n",
      "[[ 3 27]\n",
      " [24 12]]\n",
      "y_test:\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#train_test_split　を使用\n",
    "np.random.seed(0)\n",
    "ex_X = np.random.choice(30, size=(10,2), replace=True)\n",
    "print(\"ex_X:\\n{}\".format(ex_X))\n",
    "ex_y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "print(\"ex_y:\\n{}\".format(ex_y))\n",
    "print(\"--------------------\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ex_X, ex_y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train:\\n{}\".format(X_train))\n",
    "print(\"y_train:\\n{}\".format(y_train))\n",
    "print(\"X_test:\\n{}\".format(X_test))\n",
    "print(\"y_test:\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[21 18]\n",
      " [ 3 27]\n",
      " [ 3  7]\n",
      " [ 9 19]\n",
      " [21  0]\n",
      " [12 15]\n",
      " [26  1]\n",
      " [24 12]]\n",
      "y_train:\n",
      "[1 0 0 0 0 0 1 1]\n",
      "X_test:\n",
      "[[ 4 23]\n",
      " [ 6 24]]\n",
      "y_test:\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "#スクラッチした関数を使用\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(ex_X, ex_y, train_size=0.8,)\n",
    "print(\"X_train:\\n{}\".format(X_train))\n",
    "print(\"y_train:\\n{}\".format(y_train))\n",
    "print(\"X_test:\\n{}\".format(X_test))\n",
    "print(\"y_test:\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スクラッチした関数の整合性はとれていそう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1\n",
    "同じランダムシード（ランダムステート？？）で整合性の確認をしたかったがやり方がわからなかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnを使ったコードを作成していきます。\n",
    "\n",
    "\n",
    "検証データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n",
    "\n",
    "\n",
    "**分類問題**  \n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "[sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)  \n",
    "[sklearn.svm.SVC — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)  \n",
    "[sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)  \n",
    "\n",
    "データセットは3種類用意します。  \n",
    "1つ目は事前学習期間同様にirisデータセットです。  \n",
    "[sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)  \n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "- virgicolorとvirginica\n",
    "\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  petal_length  target\n",
       "50            7.0           4.7       1\n",
       "51            6.4           4.5       1\n",
       "52            6.9           4.9       1\n",
       "53            5.5           4.0       1\n",
       "54            6.5           4.6       1\n",
       "55            5.7           4.5       1\n",
       "56            6.3           4.7       1\n",
       "57            4.9           3.3       1\n",
       "58            6.6           4.6       1\n",
       "59            5.2           3.9       1\n",
       "60            5.0           3.5       1\n",
       "61            5.9           4.2       1\n",
       "62            6.0           4.0       1\n",
       "63            6.1           4.7       1\n",
       "64            5.6           3.6       1\n",
       "65            6.7           4.4       1\n",
       "66            5.6           4.5       1\n",
       "67            5.8           4.1       1\n",
       "68            6.2           4.5       1\n",
       "69            5.6           3.9       1\n",
       "70            5.9           4.8       1\n",
       "71            6.1           4.0       1\n",
       "72            6.3           4.9       1\n",
       "73            6.1           4.7       1\n",
       "74            6.4           4.3       1\n",
       "75            6.6           4.4       1\n",
       "76            6.8           4.8       1\n",
       "77            6.7           5.0       1\n",
       "78            6.0           4.5       1\n",
       "79            5.7           3.5       1\n",
       "..            ...           ...     ...\n",
       "120           6.9           5.7       2\n",
       "121           5.6           4.9       2\n",
       "122           7.7           6.7       2\n",
       "123           6.3           4.9       2\n",
       "124           6.7           5.7       2\n",
       "125           7.2           6.0       2\n",
       "126           6.2           4.8       2\n",
       "127           6.1           4.9       2\n",
       "128           6.4           5.6       2\n",
       "129           7.2           5.8       2\n",
       "130           7.4           6.1       2\n",
       "131           7.9           6.4       2\n",
       "132           6.4           5.6       2\n",
       "133           6.3           5.1       2\n",
       "134           6.1           5.6       2\n",
       "135           7.7           6.1       2\n",
       "136           6.3           5.6       2\n",
       "137           6.4           5.5       2\n",
       "138           6.0           4.8       2\n",
       "139           6.9           5.4       2\n",
       "140           6.7           5.6       2\n",
       "141           6.9           5.1       2\n",
       "142           5.8           5.1       2\n",
       "143           6.8           5.9       2\n",
       "144           6.7           5.7       2\n",
       "145           6.7           5.2       2\n",
       "146           6.3           5.0       2\n",
       "147           6.5           5.2       2\n",
       "148           6.2           5.4       2\n",
       "149           5.9           5.1       2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#irisデータセット\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris_data.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "df[\"target\"] = iris_data.target\n",
    "\n",
    "df_1 = df.loc[df[\"target\"].isin([1, 2]), [\"sepal_length\", \"petal_length\", \"target\"]]\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット1作成コード\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット2作成コード\n",
    "\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 1]\n",
      "SVC:\n",
      "[1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 2]\n",
      "決定木:\n",
      "[1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#irisデータセット\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris_data.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "df[\"target\"] = iris_data.target\n",
    "\n",
    "df_1 = df.loc[df[\"target\"].isin([1, 2]), [\"sepal_length\", \"petal_length\", \"target\"]]\n",
    "\n",
    "#データ分割\n",
    "X, y = df_1.loc[:, [\"sepal_length\",\"petal_length\" ]].values, df_1.loc[:, \"target\"].values\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "print(\"SVC:\\n{}\".format(svc.predict(X_test)))\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"決定木:\\n{}\".format(tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[ 1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1  1  1\n",
      " -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1  1]\n",
      "SVC:\n",
      "[ 1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1  1  1\n",
      " -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1  1]\n",
      "決定木:\n",
      "[ 1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1  1  1\n",
      " -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#シンプルデータセット1\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "print(\"SVC:\\n{}\".format(svc.predict(X_test)))\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"決定木:\\n{}\".format(tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[0 1 1 0 1 1 1 1]\n",
      "SVC:\n",
      "[0 1 1 1 1 1 1 1]\n",
      "決定木:\n",
      "[0 0 0 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#シンプルデータセット2\n",
    "\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "print(\"SVC:\\n{}\".format(svc.predict(X_test)))\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"決定木:\\n{}\".format(tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回帰問題**\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "\n",
    "[sklearn.linear_model.SGDRegressor — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 325000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 325000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000 285000 285000 285000 285000 285000 285000 285000 285000\n",
      " 285000 285000]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]].values\n",
    "y = df.loc[:, \"SalePrice\"].values\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier().fit(X_train, y_train)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
