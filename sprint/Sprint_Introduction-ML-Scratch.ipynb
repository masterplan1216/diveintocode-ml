{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **機械学習スクラッチ入門**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。\n",
    "\n",
    "このSprintでは機械学習手法のスクラッチ課題に取り組む準備を行います。scikit-learnを用いて分類・回帰問題を解くコードを書いておき、今後のSprintではそれと同じ動作をするクラスをスクラッチで作成していきます。\n",
    "\n",
    "**【スクラッチの意義】**  \n",
    "ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "\n",
    "\n",
    "スクラッチをすることでscikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "以下のような効果を狙っています。\n",
    "- 新たな手法に出会った時に理論・数式を理解しやすくする\n",
    "- ライブラリを使う上での曖昧さを減らす\n",
    "- 既存の実装を読みやすくする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。  \n",
    "\n",
    ">[参考1](https://www.it-swarm.dev/ja/python/numpy%ef%bc%9a2d%e9%85%8d%e5%88%97%e3%81%8b%e3%82%89%e8%a1%8c%e3%81%ae%e3%83%a9%e3%83%b3%e3%83%80%e3%83%a0%e3%82%bb%e3%83%83%e3%83%88%e3%82%92%e5%8f%96%e5%be%97%e3%81%97%e3%81%be%e3%81%99/1069900142/)  \n",
    "[参考2](https://www.sky-limit-future.com/entry/numpy-aggregate-function)  \n",
    "[numpy.random.choice](https://het.as.utexas.edu/HET/Software/Numpy/reference/generated/numpy.random.choice.html)  \n",
    "[numpy.setdiff1d](https://numpy.org/doc/stable/reference/generated/numpy.setdiff1d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      訓練データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    #Xから（Xのサンプル数*train_size）個のランダムな行をndarrayとして抜き出す\n",
    "    train_row_num = np.random.choice(X.shape[0], \\\n",
    "                                                                   size=int(Decimal(X.shape[0]*train_size).quantize(Decimal(\"0\"), rounding = ROUND_HALF_UP)), \\\n",
    "                                                                   replace=False)\n",
    "    X_train = X[train_row_num, :]\n",
    "    \n",
    "    #XとX_trainの差集合がX_test\n",
    "    test_row_num = np.setdiff1d(np.array(range(X.shape[0])), train_row_num)\n",
    "    X_test = X[test_row_num, :]\n",
    "    \n",
    "    y_train = y[train_row_num]\n",
    "    y_test = y[test_row_num]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- スクラッチした関数の整合性確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex_X:\n",
      "[[12 15]\n",
      " [21  0]\n",
      " [ 3 27]\n",
      " [ 3  7]\n",
      " [ 9 19]\n",
      " [21 18]\n",
      " [ 4 23]\n",
      " [ 6 24]\n",
      " [24 12]\n",
      " [26  1]]\n",
      "ex_y:\n",
      "[0 0 0 0 0 1 1 1 1 1]\n",
      "--------------------\n",
      "X_train:\n",
      "[[ 9 19]\n",
      " [26  1]\n",
      " [21  0]\n",
      " [ 4 23]\n",
      " [ 6 24]\n",
      " [ 3  7]\n",
      " [12 15]\n",
      " [21 18]]\n",
      "y_train:\n",
      "[0 1 0 1 1 0 0 1]\n",
      "X_test:\n",
      "[[ 3 27]\n",
      " [24 12]]\n",
      "y_test:\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#train_test_split　を使用\n",
    "np.random.seed(0)\n",
    "ex_X = np.random.choice(30, size=(10,2), replace=True)\n",
    "print(\"ex_X:\\n{}\".format(ex_X))\n",
    "ex_y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "print(\"ex_y:\\n{}\".format(ex_y))\n",
    "print(\"--------------------\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ex_X, ex_y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"X_train:\\n{}\".format(X_train))\n",
    "print(\"y_train:\\n{}\".format(y_train))\n",
    "print(\"X_test:\\n{}\".format(X_test))\n",
    "print(\"y_test:\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[21 18]\n",
      " [ 3 27]\n",
      " [ 3  7]\n",
      " [ 9 19]\n",
      " [21  0]\n",
      " [12 15]\n",
      " [26  1]\n",
      " [24 12]]\n",
      "y_train:\n",
      "[1 0 0 0 0 0 1 1]\n",
      "X_test:\n",
      "[[ 4 23]\n",
      " [ 6 24]]\n",
      "y_test:\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "#スクラッチした関数を使用\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(ex_X, ex_y, train_size=0.8,)\n",
    "print(\"X_train:\\n{}\".format(X_train))\n",
    "print(\"y_train:\\n{}\".format(y_train))\n",
    "print(\"X_test:\\n{}\".format(X_test))\n",
    "print(\"y_test:\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スクラッチした関数の整合性はとれていそう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1\n",
    "同じランダムシード（ランダムステート？？）で整合性の確認をしたかったがやり方がわからなかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learnを使ったコードを作成していきます。\n",
    "\n",
    "\n",
    "検証データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n",
    "\n",
    "\n",
    "**分類問題**  \n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "\n",
    "- ロジスティック回帰\n",
    "- SVM\n",
    "- 決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "[sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)  \n",
    "[sklearn.svm.SVC — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)  \n",
    "[sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)  \n",
    "\n",
    "データセットは3種類用意します。  \n",
    "1つ目は事前学習期間同様にirisデータセットです。  \n",
    "[sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)  \n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "- virgicolorとvirginica\n",
    "\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  petal_length  target\n",
       "50            7.0           4.7       1\n",
       "51            6.4           4.5       1\n",
       "52            6.9           4.9       1\n",
       "53            5.5           4.0       1\n",
       "54            6.5           4.6       1\n",
       "55            5.7           4.5       1\n",
       "56            6.3           4.7       1\n",
       "57            4.9           3.3       1\n",
       "58            6.6           4.6       1\n",
       "59            5.2           3.9       1\n",
       "60            5.0           3.5       1\n",
       "61            5.9           4.2       1\n",
       "62            6.0           4.0       1\n",
       "63            6.1           4.7       1\n",
       "64            5.6           3.6       1\n",
       "65            6.7           4.4       1\n",
       "66            5.6           4.5       1\n",
       "67            5.8           4.1       1\n",
       "68            6.2           4.5       1\n",
       "69            5.6           3.9       1\n",
       "70            5.9           4.8       1\n",
       "71            6.1           4.0       1\n",
       "72            6.3           4.9       1\n",
       "73            6.1           4.7       1\n",
       "74            6.4           4.3       1\n",
       "75            6.6           4.4       1\n",
       "76            6.8           4.8       1\n",
       "77            6.7           5.0       1\n",
       "78            6.0           4.5       1\n",
       "79            5.7           3.5       1\n",
       "..            ...           ...     ...\n",
       "120           6.9           5.7       2\n",
       "121           5.6           4.9       2\n",
       "122           7.7           6.7       2\n",
       "123           6.3           4.9       2\n",
       "124           6.7           5.7       2\n",
       "125           7.2           6.0       2\n",
       "126           6.2           4.8       2\n",
       "127           6.1           4.9       2\n",
       "128           6.4           5.6       2\n",
       "129           7.2           5.8       2\n",
       "130           7.4           6.1       2\n",
       "131           7.9           6.4       2\n",
       "132           6.4           5.6       2\n",
       "133           6.3           5.1       2\n",
       "134           6.1           5.6       2\n",
       "135           7.7           6.1       2\n",
       "136           6.3           5.6       2\n",
       "137           6.4           5.5       2\n",
       "138           6.0           4.8       2\n",
       "139           6.9           5.4       2\n",
       "140           6.7           5.6       2\n",
       "141           6.9           5.1       2\n",
       "142           5.8           5.1       2\n",
       "143           6.8           5.9       2\n",
       "144           6.7           5.7       2\n",
       "145           6.7           5.2       2\n",
       "146           6.3           5.0       2\n",
       "147           6.5           5.2       2\n",
       "148           6.2           5.4       2\n",
       "149           5.9           5.1       2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#irisデータセット\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris_data.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "df[\"target\"] = iris_data.target\n",
    "\n",
    "df_1 = df.loc[df[\"target\"].isin([1, 2]), [\"sepal_length\", \"petal_length\", \"target\"]]\n",
    "display(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット1作成コード\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シンプルデータセット2作成コード\n",
    "\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 1]\n",
      "SVC:\n",
      "[1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2 2]\n",
      "決定木:\n",
      "[1 1 1 1 1 1 1 1 2 1 2 2 2 2 2 2 2 2 2 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#irisデータセット\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris_data.data, columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"])\n",
    "df[\"target\"] = iris_data.target\n",
    "\n",
    "df_1 = df.loc[df[\"target\"].isin([1, 2]), [\"sepal_length\", \"petal_length\", \"target\"]]\n",
    "\n",
    "#データ分割\n",
    "X, y = df_1.loc[:, [\"sepal_length\",\"petal_length\" ]].values, df_1.loc[:, \"target\"].values\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "print(\"SVC:\\n{}\".format(svc.predict(X_test)))\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"決定木:\\n{}\".format(tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[ 1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1  1  1\n",
      " -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1  1]\n",
      "SVC:\n",
      "[ 1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1  1  1\n",
      " -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1  1]\n",
      "決定木:\n",
      "[ 1  1 -1 -1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1\n",
      " -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1  1 -1 -1  1 -1  1  1  1\n",
      " -1 -1  1 -1  1 -1  1  1  1  1  1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1\n",
      "  1  1 -1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#シンプルデータセット1\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "print(\"SVC:\\n{}\".format(svc.predict(X_test)))\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"決定木:\\n{}\".format(tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[0 1 1 0 1 1 1 1]\n",
      "SVC:\n",
      "[0 1 1 1 1 1 1 1]\n",
      "決定木:\n",
      "[0 0 0 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#シンプルデータセット2\n",
    "\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "#ロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"log\").fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC().fit(X_train, y_train)\n",
    "print(\"SVC:\\n{}\".format(svc.predict(X_test)))\n",
    "\n",
    "#決定木\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print(\"決定木:\\n{}\".format(tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**回帰問題**\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "\n",
    "- 線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "\n",
    "[sklearn.linear_model.SGDRegressor — scikit-learn 0.21.3 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ロジスティック回帰:\n",
      "[-2.78799678e+15 -1.57658661e+15 -2.54483442e+15 -1.43532056e+15\n",
      " -3.76942706e+14 -3.83082942e+15 -2.40780465e+15  1.37704777e+14\n",
      " -4.28700416e+15 -1.00931420e+14 -8.27788270e+14 -2.36803341e+15\n",
      " -5.23260959e+14 -1.29417906e+15 -2.13885312e+15 -4.52053576e+14\n",
      "  2.03040594e+13 -3.04196995e+15 -1.10726071e+15 -1.56804534e+15\n",
      " -3.56082580e+15 -1.51581643e+15 -1.37713979e+15 -3.30141183e+15\n",
      " -8.91880081e+14 -2.38057822e+14 -2.38676281e+15 -2.58406462e+15\n",
      " -2.41694069e+15 -3.91910435e+15 -3.63791632e+15 -5.57860532e+15\n",
      " -1.93817387e+15 -2.57427800e+15 -8.70909044e+14 -1.40612605e+15\n",
      " -2.22705860e+14 -1.12586558e+15 -1.42971440e+15 -5.69739091e+15\n",
      " -2.51604142e+15 -1.99297720e+15 -2.14631440e+15 -1.48073878e+15\n",
      " -2.38057822e+14  6.52241369e+13 -4.18393122e+15 -1.74317206e+13\n",
      " -1.92113557e+14 -1.27336046e+15 -2.76942324e+14 -1.02252858e+15\n",
      " -1.54878989e+15 -2.53783389e+14 -3.40063709e+15 -9.37575275e+14\n",
      " -3.55018035e+15 -4.44526903e+15 -2.66453258e+15 -2.83035535e+15\n",
      " -3.17487507e+15 -2.33291494e+15 -1.27066285e+14 -1.84683929e+15\n",
      " -1.10778676e+15 -1.01629974e+15 -2.05068774e+15 -2.20700086e+15\n",
      " -1.61065298e+15 -1.70402302e+15 -1.35182087e+15 -1.40064443e+15\n",
      " -2.43789881e+15 -3.41407740e+14 -2.83130339e+14 -1.29586881e+15\n",
      " -1.16173126e+15 -1.70040942e+15 -2.90874703e+15 -2.10259885e+15\n",
      " -4.16495275e+15 -2.17888635e+15 -3.62169261e+15 -3.69287209e+15\n",
      " -7.24936492e+14 -5.45616873e+14 -5.22165584e+15 -1.70962918e+15\n",
      " -2.39325571e+15 -3.08863694e+14 -1.11670163e+15 -1.61111030e+15\n",
      " -2.65041306e+15 -2.53190444e+15 -9.90053255e+14 -1.94906840e+15\n",
      " -1.34764040e+15 -3.15732229e+15 -1.83877168e+14 -3.45233996e+15\n",
      " -2.82031966e+15 -3.72275800e+15  1.06655154e+14 -3.69328993e+14\n",
      " -3.53426152e+15 -1.67668362e+15 -2.56317523e+15 -2.48896401e+15\n",
      " -8.74009510e+14 -3.40621535e+15 -1.98925406e+15 -2.90186762e+15\n",
      " -2.00024521e+15 -3.67216304e+15 -1.73649834e+15 -2.72099776e+15\n",
      " -5.05459113e+14 -2.59232892e+15 -7.26888236e+14 -1.89070728e+15\n",
      " -1.67675235e+15 -2.99237127e+15 -9.58810371e+14 -1.65728894e+13\n",
      " -2.10329025e+15 -2.70895452e+15 -8.29186063e+14 -2.15329044e+15\n",
      "  4.86654025e+14 -2.82713035e+15 -1.03472426e+15 -2.98169791e+15\n",
      " -8.73303119e+14 -2.89636151e+14  1.77765906e+14 -1.15622173e+15\n",
      " -4.46170441e+14 -1.93346736e+15 -4.61712738e+15 -4.79019368e+14\n",
      " -1.69757644e+14 -2.80979874e+15 -3.18553686e+14 -1.90557402e+15\n",
      " -1.50460411e+15 -1.88337054e+15 -1.95430095e+15 -2.59598333e+15\n",
      " -3.32054274e+15 -5.64623251e+14 -2.27167453e+15 -2.50336051e+15\n",
      " -1.94594003e+15 -1.37370654e+15  7.22559942e+13 -2.51053189e+15\n",
      " -8.13668746e+14 -6.03202872e+14 -2.63304063e+15  6.46151043e+12\n",
      " -2.90945342e+15 -5.20381659e+14 -1.84969069e+15 -5.32605785e+15\n",
      " -1.84910883e+15 -8.24161759e+14 -1.58890683e+15 -3.26673569e+15\n",
      " -2.65549659e+14 -9.72652920e+14 -4.04560029e+15 -2.53907924e+14\n",
      " -2.03539159e+15 -3.67224810e+14 -2.09117828e+15 -1.25144688e+15\n",
      " -1.98807743e+15 -1.76749215e+15 -2.60907867e+15 -4.09886630e+15\n",
      " -2.31080810e+15 -2.52477595e+15 -2.79375538e+15 -4.08838828e+15\n",
      " -1.09837374e+15 -2.65041306e+15 -2.38458990e+15 -2.33477006e+15\n",
      " -2.75802715e+15 -4.66450076e+14 -4.97873305e+14 -3.34795086e+15\n",
      " -1.72500904e+15 -1.66601368e+14 -2.82124722e+15 -5.16982844e+15\n",
      " -3.22199596e+15 -4.53755907e+15 -4.21280928e+14 -6.95284662e+14\n",
      " -2.43960148e+15 -1.97708628e+15 -9.00228090e+14 -1.97132768e+15\n",
      " -6.01919403e+15 -4.91081598e+15 -4.16142287e+15 -2.38576653e+15\n",
      " -4.93645270e+15 -5.04310391e+14 -1.38735583e+15 -3.45944054e+15\n",
      " -1.90018902e+15 -1.21001586e+15 -8.36835249e+13 -1.30302521e+15\n",
      " -6.84750828e+14 -3.26413337e+15 -1.14308557e+15 -1.64938504e+15\n",
      " -4.16200814e+14 -1.13286953e+15 -3.45874914e+15 -6.04379499e+14\n",
      " -5.93388345e+14 -2.11581872e+15 -3.28258579e+15 -2.25715349e+15\n",
      " -5.72803830e+14 -7.30708008e+14 -1.10101689e+15 -4.45491955e+14\n",
      " -5.91561137e+14 -3.89082583e+14 -1.91603912e+15 -7.86163265e+13\n",
      " -1.81253677e+15 -2.58489897e+14 -2.45805391e+15 -8.09584779e+15\n",
      " -5.92550619e+15 -4.89707006e+15 -9.94482788e+14 -1.83312128e+15\n",
      " -1.66947142e+15 -5.67876156e+14 -1.18785321e+15 -2.53789919e+15\n",
      " -2.88460473e+15 -2.32495553e+15 -2.50164492e+15 -3.04410204e+15\n",
      " -6.52178877e+14 -3.91677900e+15 -2.41133453e+15 -2.26235741e+14\n",
      " -2.08421515e+15 -2.05950598e+15 -1.60219543e+15 -2.93270899e+15\n",
      " -4.78769748e+15 -2.42350231e+15 -4.60351891e+15 -2.55988150e+15\n",
      " -2.39628745e+15 -1.57974288e+15 -5.13122091e+15 -2.33058960e+15\n",
      " -2.80802734e+15 -1.61228693e+15 -3.23956165e+15 -3.89216646e+15\n",
      " -5.22875642e+15 -1.70525546e+15 -3.75452719e+12 -5.20381659e+14\n",
      " -2.35648758e+14 -5.68860057e+15 -1.22315202e+15 -2.24638350e+15\n",
      " -2.76942324e+14 -4.78728305e+15 -2.09725468e+15 -1.36549806e+15\n",
      " -6.28499390e+13 -2.93301387e+15 -2.11693954e+15 -1.62817785e+15\n",
      " -2.83704151e+15 -2.18086600e+15 -9.22085863e+14 -1.15766241e+15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itonaoki/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]].values\n",
    "y = df.loc[:, \"SalePrice\"].values\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8,)\n",
    "\n",
    "#学習、推定\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "clf = SGDRegressor().fit(X_train, y_train)\n",
    "print(\"ロジスティック回帰:\\n{}\".format(clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
