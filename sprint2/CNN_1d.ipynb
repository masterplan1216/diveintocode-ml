{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sprintの目的\n",
    "- スクラッチを通してCNNの基礎を理解する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#np.set_printoptions(threshold=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込みニューラルネットワーク（CNN） のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "このSprintでは1次元の 畳み込み層 を作成し、畳み込みの基礎を理解することを目指します。次のSprintでは2次元畳み込み層とプーリング層を作成することで、一般的に画像に対して利用されるCNNを完成させます。\n",
    "\n",
    "\n",
    "クラスの名前はScratch1dCNNClassifierとしてください。クラスの構造などは前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1次元畳み込み層とは\n",
    "CNNでは画像に対しての2次元畳み込み層が定番ですが、ここでは理解しやすくするためにまずは1次元畳み込み層を実装します。1次元畳み込みは実用上は自然言語や波形データなどの 系列データ で使われることが多いです。\n",
    "\n",
    "\n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまではフレームワークで一般的に用意されています。\n",
    "\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの用意\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (48000, 10)\n",
      "(12000, 784) (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#平滑化、正規化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#ワンホットエンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, y_train.shape) # (48000, 784)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s + b\n",
    "$$\n",
    "$a_i$ : 出力される配列のi番目の値\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s)}$ : 入力の配列の(i+s)番目の値\n",
    "\n",
    "\n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "\n",
    "\n",
    "$b$ : バイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "$$\n",
    "w_s' = w_s - α\\frac{∂L}{∂w_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b' = b - α\\frac{∂L}{∂b}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_s}$ や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "$$\n",
    "\\frac{∂L}{∂w_s} = \\sum_{i=0}^{N_{out} - 1}\\frac{∂L}{∂a_i}x_{(i + s)}\n",
    "$$\n",
    "$$\n",
    "\\frac{∂L}{∂b} = \\sum_{i=0}^{N_{out} - 1}\\frac{∂L}{∂a_i}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi番目の値\n",
    "\n",
    "\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{∂L}{∂x_i} = \\sum_{s=0}^{F-1}\\frac{∂L}{∂a_{(j-s)}}w_s\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "\n",
    "ただし、 $j-s<0$ または $j-s>N_{out}-1$ のとき $\\frac{\\partial L}{\\partial a_{(j-s)}} =0$ です。\n",
    "\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    def __init__(self, initializer, optimizer, S=1, P=0):\n",
    "        self.w = initializer.W()\n",
    "        self.b = initializer.B()\n",
    "        self.optimizer = optimizer\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        \"\"\"\n",
    "        Z : 順伝播された特徴量データ\n",
    "        \"\"\"\n",
    "        out_shape = calc_out_shape(Z, self.P, self.w, self.S)\n",
    "        #indexの配列作成\n",
    "        id_A = np.arange(out_shape).reshape(-1, 1)\n",
    "        id_w = np.arange(len(self.w))\n",
    "        id_array = id_A + id_w\n",
    "        A = Z[id_array] @ self.w.T + self.b\n",
    "        \n",
    "        #参考\n",
    "        #stride_data = np.array([X[i:i+3] for i in range(out_shape)]) \n",
    "        #A = stride_data @ self.w.T + self.b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, Z, dA):\n",
    "        \"\"\"\n",
    "        Z : 順伝播された特徴量データ\n",
    "        dA : 逆伝播されたAに関するLoss勾配\n",
    "        \"\"\"\n",
    "        #indexの配列作成\n",
    "        id_dA = np.arange(len(dA))\n",
    "        id_w = np.arange(len(self.w))\n",
    "        \n",
    "        #db\n",
    "        self.db = np.sum(dA, axis=0)\n",
    "        \n",
    "        #dw\n",
    "        id_array_dw = id_dA.reshape(-1, 1) + id_w\n",
    "        self.dw = dA @ Z[id_array_dw]\n",
    "        \n",
    "        #dZ\n",
    "        id_array_dZ = id_Z - id_dA\n",
    "        mask = np.where((id_array_dZ < 0) | (id_array_dZ > n_out)) # | はorの意味\n",
    "        id_array_dZ[mask] = 0\n",
    "        w_mask = w[id_array_dZ]\n",
    "        w_mask[mask] = 0\n",
    "        self.dZ = dA @ w_mask.T\n",
    "        \n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_shape(IN, P, F, S):\n",
    "    \"\"\"\n",
    "    「入力データ、パディング、フィルタ、ストライド」を受け取り、出力データのサイズを返す\n",
    "    2次元データまで対応\n",
    "    \"\"\"\n",
    "    if IN.ndim == 1:\n",
    "        out_shape = int((len(IN) + 2*P - len(F))/S + 1)\n",
    "    else:\n",
    "        in_h, in_w = IN.shape\n",
    "        f_h, f_w = F.shape\n",
    "        out_h = int((in_h + 2*P - f_h)/S + 1)\n",
    "        out_w = int((in_w + 2*P - f_w)/S + 1)\n",
    "        out_shape = out_h, out_w\n",
    "    \n",
    "    return out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_dA：\n",
      " [0 1]\n",
      "id_Z：\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "id_w：\n",
      " [[0]\n",
      " [1]\n",
      " [2]]\n",
      "[[ 0 -1]\n",
      " [ 1  0]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n",
      "(array([0, 3]), array([1, 0]))\n",
      "id_array_dZ:\n",
      " [[0 0]\n",
      " [1 0]\n",
      " [2 1]\n",
      " [0 2]]\n",
      "w_mask1:\n",
      " [[3 3]\n",
      " [5 3]\n",
      " [7 5]\n",
      " [3 7]]\n",
      "w_mask2:\n",
      " [[3 0]\n",
      " [5 3]\n",
      " [7 5]\n",
      " [0 7]]\n",
      "dZ:\n",
      " [ 30 110 170 140]\n"
     ]
    }
   ],
   "source": [
    "#参考\n",
    "P = 0\n",
    "S = 1\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "dA = np.array([10, 20])\n",
    "\n",
    "n_out = calc_out_shape(x, P, w, S)\n",
    "\n",
    "id_dA = np.arange(dA.shape[0])  #dA分のindexを生成\n",
    "print(\"id_dA：\\n\", id_dA)\n",
    "id_Z = np.arange(x.shape[0])[:,None]  #出力層分のindexを生成\n",
    "print(\"id_Z：\\n\", id_Z)\n",
    "id_w = np.arange(w.shape[0])[:,None]  #フィルタ数分のindexを生成\n",
    "print(\"id_w：\\n\", id_w)\n",
    "\n",
    "# dZ計算\n",
    "id_array_dZ = id_Z - id_dA  #ブロードキャスト用index\n",
    "print(id_array_dZ)\n",
    "mask = np.where((id_array_dZ < 0) | (id_array_dZ > n_out))\n",
    "print(mask)\n",
    "id_array_dZ[mask] = 0\n",
    "print(\"id_array_dZ:\\n\", id_array_dZ)\n",
    "w_mask = w[id_array_dZ]\n",
    "print(\"w_mask1:\\n\", w_mask)\n",
    "w_mask[mask] = 0\n",
    "print(\"w_mask2:\\n\", w_mask)\n",
    "dZ = np.sum(w_mask * dA, axis = 1)\n",
    "print(\"dZ:\\n\", dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{out} = \\frac{N_{in} + 2P - F}{S} + 1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_shape(IN, P, F, S):\n",
    "    \"\"\"\n",
    "    「入力データ、パディング、フィルタ、ストライド」を受け取り、出力データのサイズを返す\n",
    "    2次元データまで対応\n",
    "    \"\"\"\n",
    "    if IN.ndim == 1:\n",
    "        out_shape = int((len(IN) + 2*P - len(F))/S + 1)\n",
    "    else:\n",
    "        in_h, in_w = IN.shape\n",
    "        f_h, f_w = F.shape\n",
    "        out_h = int((in_h + 2*P - f_h)/S + 1)\n",
    "        out_w = int((in_w + 2*P - f_w)/S + 1)\n",
    "        out_shape = out_h, out_w\n",
    "    \n",
    "    return out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#検証（1次元データの場合）\n",
    "P = 0\n",
    "S = 1\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "\n",
    "calc_out_shape(x, P, w, S) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#検証(2次元データの場合)\n",
    "IN = np.arange(16).reshape(4, 4)\n",
    "P = 1\n",
    "F = np.arange(9).reshape(3, 3)\n",
    "S = 1\n",
    "\n",
    "calc_out_shape(IN, P, F, S) #(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_shape(IN, f_size, S=1, P=0):\n",
    "    return int((IN + 2*P - f_size) // S + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d_test:\n",
    "    def __init__(self, w, b, S=1, P=0):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        \"\"\"\n",
    "        Z : 順伝播された特徴量データ\n",
    "        \"\"\"\n",
    "        out_shape = calc_out_shape(Z, self.P, self.w, self.S)\n",
    "        #indexの配列作成\n",
    "        id_A = np.arange(out_shape).reshape(-1, 1)\n",
    "        id_w = np.arange(len(self.w))\n",
    "        id_array = id_A + id_w\n",
    "        A = Z[id_array] @ self.w.T + self.b\n",
    "        \n",
    "        #参考\n",
    "        #stride_data = np.array([X[i:i+3] for i in range(out_shape)]) \n",
    "        #A = stride_data @ self.w.T + self.b\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, Z, dA):\n",
    "        \"\"\"\n",
    "        Z : 順伝播された特徴量データ\n",
    "        dA : 逆伝播されたAに関するLoss勾配\n",
    "        \"\"\"\n",
    "        #indexの配列作成\n",
    "        id_dA = np.arange(len(dA))\n",
    "        id_w = np.arange(len(self.w))\n",
    "        \n",
    "        #db\n",
    "        self.db = np.sum(dA, axis=0)\n",
    "        \n",
    "        #dw\n",
    "        id_array_dw = id_dA.reshape(-1, 1) + id_w\n",
    "        self.dw = dA @ Z[id_array_dw]\n",
    "        \n",
    "        #dZ\n",
    "        id_array_dZ = id_Z - id_dA\n",
    "        mask = np.where((id_array_dZ < 0) | (id_array_dZ > n_out)) # | はorの意味\n",
    "        id_array_dZ[mask] = 0\n",
    "        w_mask = w[id_array_dZ]\n",
    "        w_mask[mask] = 0\n",
    "        self.dZ = dA @ w_mask.T\n",
    "        \n",
    "        return self.db, self.dw, self.dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#検証\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "dA = np.array([10, 20])\n",
    "\n",
    "test = SimpleConv1d_test(w, b)\n",
    "test.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, array([ 50,  80, 110]), array([ 30, 110, 170, 140]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backward(x, dA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diverの例と一致している"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。  \n",
    "例えば以下の入力があった場合、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "display(x)\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "display(w)\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "display(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力は以下のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 22],\n",
       "       [17, 23],\n",
       "       [18, 24]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#魚本より\n",
    "\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_1d(input_data, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 幅)の3次元配列からなる入力データ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, W = input_data.shape\n",
    "    out_size = get_out_shape(W, filter_w, stride, pad)\n",
    "\n",
    "    img = np.pad(input_data, [(0, 0), (0, 0), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_w, out_size))\n",
    "\n",
    "    for x in range(filter_w):\n",
    "        x_max = x + stride * out_size\n",
    "        col[:, :, x, :] = img[:, :, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 3, 1, 2)\n",
    "    col = col.reshape(N * out_size, -1)\n",
    "    return col\n",
    "\n",
    "\n",
    "def col2im_1d(col, input_shape, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    N, C, W = input_shape\n",
    "    out_size = get_out_shape(W, filter_w, stride, pad)\n",
    "\n",
    "    col = col.reshape(N, out_size, C, filter_w).transpose(0, 2, 3, 1)\n",
    "    img = np.zeros((N, C, W + 2 * pad +  stride - 1))\n",
    "    for x in range(filter_w):\n",
    "        x_max = x + stride * out_size\n",
    "        img[:, :, x:x_max:stride] += col[:, :, x, :]\n",
    "\n",
    "    return img[:, :, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x__ :\n",
      " [[[[1 2 3 4]]\n",
      "\n",
      "  [[2 3 4 5]]]]\n",
      "(1, 2, 1, 4)\n",
      "\n",
      "\n",
      "[[1. 2. 3. 2. 3. 4.]\n",
      " [2. 3. 4. 3. 4. 5.]]\n",
      "[[[[1. 4. 6. 4.]]\n",
      "\n",
      "  [[2. 6. 8. 5.]]]]\n",
      "-----------------------------\n",
      "x_ :\n",
      " [[[1 2 3 4]\n",
      "  [2 3 4 5]]]\n",
      "(1, 2, 4)\n",
      "\n",
      "\n",
      "[[1. 2. 3. 2. 3. 4.]\n",
      " [2. 3. 4. 3. 4. 5.]]\n",
      "[[[1. 4. 6. 4.]\n",
      "  [2. 6. 8. 5.]]]\n"
     ]
    }
   ],
   "source": [
    "# 「im2col と im2col_1d」 及び 「col2im と col2im_1d」の整合性確認\n",
    "\n",
    "x__ = x[np.newaxis, :, np.newaxis, :]\n",
    "print(\"x__ :\\n\", x__)\n",
    "print(x__.shape)\n",
    "print(\"\\n\")\n",
    "print(im2col(x__, 1, 3))\n",
    "print(col2im(im2col(x__, 1, 3), x__.shape, 1, 3))\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "x_ = x[np.newaxis, :, :]\n",
    "print(\"x_ :\\n\", x_)\n",
    "print(x_.shape)\n",
    "print(\"\\n\")\n",
    "print(im2col_1d(x_, 3))\n",
    "print(col2im_1d(im2col_1d(x_, 3), x_.shape, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "\n",
    "def get_out_shape(IN, f_size, S=1, P=0):\n",
    "    return int((IN + 2*P - f_size) // S + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    def __init__(self, w, b, stride=1, pad=0):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.X =None\n",
    "        self.col = None\n",
    "        self.col_w = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        FN, C, FL = self.w.shape #n_filters(=out_channels), n_channels, filter_length\n",
    "        N, C, L = X.shape #n_samples, n_channels, n_features\n",
    "        out_size = get_out_shape(L, FL, self.stride, self.pad)\n",
    "        \n",
    "        col = im2col_1d(X, FL, self.stride, self.pad)\n",
    "        col_w = self.w.reshape(FN, -1).T\n",
    "\n",
    "        out = col @ col_w + self.b\n",
    "        out = out.reshape(N, out_size, -1).transpose(0, 2, 1)\n",
    "        \n",
    "        # バックワード用\n",
    "        self.X = X\n",
    "        self.col = col\n",
    "        self.col_w = col_w\n",
    "        return out\n",
    "\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FL = self.w.shape #n_filters, n_channels, filter_length\n",
    "        dout = dout.transpose(0, 2, 1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dw = self.col.T @ dout\n",
    "        self.dw = self.dw.transpose(1, 0).reshape(FN, C, FL)\n",
    "        \n",
    "        dcol = dout @ self.col_w.T\n",
    "        dx = col2im_1d(dcol, self.X.shape, FL, self.stride, self.pad)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[16. 22.]\n",
      "  [17. 23.]\n",
      "  [18. 24.]]]\n",
      "(1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]]])\n",
    "test = Conv1d(w, b)\n",
    "print(test.forward(X))\n",
    "print(test.forward(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考\n",
    "\n",
    "class Conv1d_:\n",
    "    def __init__(self, w, b, S=1, P=0):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        self.out_shape = calc_out_shape(Z[0], self.P, self.w[0][0], self.S)\n",
    "        \n",
    "        self.Z = Z\n",
    "        \n",
    "        #格納用\n",
    "        A = np.zeros((self.w.shape[0], self.out_shape))\n",
    "        \n",
    "        for i in range(self.w.shape[0]):\n",
    "            for j in range(self.Z.shape[0]):\n",
    "                for s in range(self.out_shape):\n",
    "                    A[i, j] = A[i, j] + np.dot(self.Z[j, s: s+self.w.shape[2]], self.w[i, j])\n",
    "                    \n",
    "        A = A + self.b.reshape(-1, 1)\n",
    "\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = Conv1d_(w, b)\n",
    "test2.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diverの例と一致している"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。\n",
    "\n",
    "\n",
    "[numpy.pad — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connected Layer Class\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.wとself.bを初期化する\n",
    "        self.w = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.b = initializer.B(n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        out = np.dot(self.X, self.w) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dX = np.dot(dout, self.w.T)\n",
    "        self.dw = np.dot(self.X.T, dout)\n",
    "        self.db = np.sum(dout, axis=0, keepdims=True)\n",
    "        \n",
    "        # 重みとバイアスの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dX\n",
    "    \n",
    "##########################################\n",
    "class Conv1d:\n",
    "    def __init__(self, initializer, optimizer, stride=1, pad=0):\n",
    "        self.w = initializer.w(n_in=1, n_out=1, fillter_size=700)\n",
    "        self.b = initializer.b(n_out=1)\n",
    "        self.optimizer = optimizer\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 中間データ（backward時に使用）\n",
    "        self.X =None\n",
    "        self.col = None\n",
    "        self.col_w = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_ = X[:, np.newaxis, :]\n",
    "        #print(X_.shape)\n",
    "        FN, C, FL = self.w.shape #n_filters(=out_channels), n_channels, filter_length\n",
    "        N, C, L = X_.shape #n_samples, n_channels, n_features\n",
    "        out_size = get_out_shape(L, FL, self.stride, self.pad)\n",
    "        \n",
    "        col = im2col_1d(X_, FL, self.stride, self.pad)\n",
    "        col_w = self.w.reshape(FN, -1).T\n",
    "        \n",
    "#         print(col.shape)\n",
    "#         print(col_w.shape)\n",
    "#         print((col@col_w).shape)\n",
    "#         print((col@col_w + self.b).shape)\n",
    "        \n",
    "        out = col @ col_w + self.b\n",
    "        out = out.reshape(N, out_size, -1).transpose(0, 2, 1)\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(X.shape[0], -1)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        # バックワード用\n",
    "        self.X_ = X_\n",
    "        self.col = col\n",
    "        self.col_w = col_w\n",
    "        return out\n",
    "\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FL = self.w.shape #n_filters, n_channels, filter_length\n",
    "        dout = dout[:, np.newaxis, :]\n",
    "        #print(\"dout\", dout.shape)\n",
    "        dout = dout.transpose(0, 2, 1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dw = self.col.T @ dout\n",
    "        self.dw = self.dw.transpose(1, 0).reshape(FN, C, FL)\n",
    "        \n",
    "        dcol = dout @ self.col_w.T\n",
    "        dx = col2im_1d(dcol, self.X_.shape, FL, self.stride, self.pad)\n",
    "        \n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return dx\n",
    "\n",
    "###########################\n",
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.w = layer.w - self.lr*layer.dw\n",
    "        layer.b = layer.b - self.lr*layer.db\n",
    "\n",
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h_w = 0\n",
    "        self.h_b = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.h_w = self.h_w + (layer.dw**2).sum()\n",
    "        self.h_b = self.h_b + (layer.db**2).sum()\n",
    "        \n",
    "        layer.w = layer.w - self.lr*(1/np.sqrt(self.h_w) + 1e-7)*layer.dw #「1e-7」で0での除算を防ぐ\n",
    "        layer.b = layer.b - self.lr*(1/np.sqrt(self.h_b) + 1e-7)*layer.db\n",
    "        \n",
    "#################################\n",
    "class XavierInitializer:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1/np.sqrt(n_nodes1)\n",
    "        W = self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = np.zeros(n_nodes2)\n",
    "        return B\n",
    "\n",
    "class XavierInitializer_conv:\n",
    "    def __init__(self):\n",
    "        self.sigma = None\n",
    "        \n",
    "    def w(self, n_in, n_out, fillter_size):\n",
    "        sigma = 1/np.sqrt(n_in)\n",
    "        if fillter_size == None:\n",
    "            w = sigma * np.random.randn(n_in, n_out) #重みの初期値(全結合層)\n",
    "        else:\n",
    "            w = sigma * np.random.randn(n_out, n_in, fillter_size) #重みの初期値（畳み込み層）\n",
    "        return w\n",
    "\n",
    "    def b(self, n_out):\n",
    "        sigma = 1/np.sqrt(n_out)\n",
    "        b = sigma * np.random.randn(n_out) #バイアスの初期値\n",
    "        return b\n",
    "\n",
    "###############################\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x < 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx\n",
    "\n",
    "##################################\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def _softmax(self, X):\n",
    "        X = X - np.max(X, axis=-1, keepdims=True)\n",
    "        y = np.exp(X) / np.sum(np.exp(X), axis=-1, keepdims=True)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def forward(self, X, t):\n",
    "        self.t = t\n",
    "        self.y = self._softmax(X)\n",
    "        self.loss = self._cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def _cross_entropy_error(self, y, t):     \n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dX = (self.y - self.t)/batch_size\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    def __init__(self, lr, fillter_size=3, batch_size=20, max_iter=3):\n",
    "        self.fillter_size = fillter_size\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "        \n",
    "        # レイヤの生成\n",
    "        initializer = XavierInitializer()\n",
    "        initializer_conv = XavierInitializer_conv()\n",
    "        optimizer = SGD(lr=lr)\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers[\"Conv1d\"] = Conv1d(initializer_conv, optimizer, pad=0, stride=1)\n",
    "        self.layers[\"ReLU\"] = Relu()\n",
    "        self.layers[\"FC1\"] = FC(85, 100, initializer, optimizer)\n",
    "        self.layers[\"ReLU_2\"] = Relu()\n",
    "        self.layers[\"FC2\"] = FC(100, 50, initializer, optimizer)\n",
    "        self.layers[\"ReLU_3\"] = Relu()\n",
    "        self.layers[\"FC3\"] = FC(50, 10, initializer, optimizer)\n",
    "        self.lastLayer = Softmax()\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # 1エポックの繰り返し数\n",
    "        iter_num = int(len(X) / self.batch_size)\n",
    "            \n",
    "        # エポックを複数回繰り返す\n",
    "        for i_ in range(self.max_iter):\n",
    "            # 損失計算用\n",
    "            tmp_loss_train = []\n",
    "            tmp_loss_val = []\n",
    "\n",
    "            # 1エポック\n",
    "            for j_ in range(iter_num):\n",
    "                batch_mask = np.random.choice(X.shape[0], self.batch_size)\n",
    "                batch_mask_val = np.random.choice(X_val.shape[0], self.batch_size)\n",
    "                X_batch = X[batch_mask]\n",
    "                y_batch = y[batch_mask]\n",
    "                X_val_batch = X_val[batch_mask_val]\n",
    "                y_val_batch = y_val[batch_mask_val]\n",
    "                \n",
    "                #勾配\n",
    "                self.gradient(X_batch, y_batch)\n",
    "                \n",
    "                #更新\n",
    "                loss = self.loss(X_batch, y_batch)\n",
    "                tmp_loss_train.append(loss)\n",
    "                if (X_val is not None) and (y_val is not None):\n",
    "                    loss_test = self.loss(X_val_batch, y_val_batch)\n",
    "                    tmp_loss_val.append(loss_test)\n",
    "                \n",
    "                #print(i_, j_)\n",
    "                    \n",
    "            self.train_loss.append(sum(tmp_loss_train)/len(tmp_loss_train))\n",
    "            self.test_loss.append(sum(tmp_loss_val)/len(tmp_loss_val))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def loss(self, X, t):\n",
    "        for layer in self.layers.values():\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return self.lastLayer.forward(X, t)\n",
    "\n",
    "    def gradient(self, X, t):\n",
    "        #forward\n",
    "        self.loss(X, t)\n",
    "        \n",
    "        #backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 784) (400, 10)\n",
      "(100, 784) (100, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#平滑化、正規化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#ワンホットエンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train[:500], y_train_one_hot[:500], test_size=0.2)\n",
    "\n",
    "print(X_train.shape, y_train.shape) # (48000, 784)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デフォルトのデータ数だと学習に時間がかかりすぎるので、流れを確認できれば良いと思いデータ数を減らした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = ScratchDeepNeuralNetrowkClassifier(lr=0.1, batch_size=20, max_iter=10)\n",
    "dnn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "予測： [9 9 2 6 4 8 6 6 3 3 0 3 5 7 1 3 5 5 7 6 3 4 2 8 5 5 6 4 9 6 1 6 6 1 1 1 8\n",
      " 1 9 2 3 9 1 4 4 4 2 9 3 1 5 9 3 2 7 1 7 8 5 3 7 3 1 1 3 6 0 0 1 3 5 9 4 5\n",
      " 0 4 4 8 0 8 3 4 9 8 7 4 5 0 7 7 7 6 0 8 2 1 5 4 3 8]\n",
      "正答率:0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "y_pred = dnn.predict(X_val)\n",
    "\n",
    "print(\"予測：\", y_pred)\n",
    "print(\"正答率:{}\".format(accuracy_score(y_pred, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8VFXex/HPSTKkJwSSkAYktNCLRDrSlGZBRRE7ri4qsqirPuLaEV2ffVx1VQSxFwRcEGRXBAFBmpTQQ+gQSAglJKSSkHaeP+4EAiQkDJPczMzv/XrNK1Nu7v1lXvCdM+eee47SWiOEEMK5uJldgBBCCPuTcBdCCCck4S6EEE5Iwl0IIZyQhLsQQjghCXchhHBCEu5CCOGEJNyFEMIJSbgLIYQT8jDrwMHBwTo6OtqswwshhEPatGnTKa11SFXbmRbu0dHRxMfHm3V4IYRwSEqpw9XZTrplhBDCCUm4CyGEE5JwF0IIJ2Ran7sQwvkUFRWRkpJCQUGB2aU4PC8vL6KiorBYLDb9fpXhrpRqDHwDhAGlwHSt9b8u2qY/8BNwyPrUj1rrSTZVJIRwWCkpKfj7+xMdHY1SyuxyHJbWmvT0dFJSUoiJibFpH9VpuRcDz2itNyul/IFNSqklWuvEi7ZbpbW+yaYqhBBOoaCgQILdDpRSNGzYkLS0NJv3UWWfu9b6mNZ6s/V+DrALiLT5iEIIpybBbh9X+z5e0QlVpVQ00AVYX8HLPZVS25RSvyil2l1VVZdzOgl+mQglRTV2CCGEcHTVDnellB8wF3hKa5190cubgaZa607Ah8D8SvYxVikVr5SKt/nrxsldsH4qxH9p2+8LIYQLqFa4K6UsGME+Q2v948Wva62ztda51vsLAYtSKriC7aZrreO01nEhIVVePVuxVkMhui+s+DvkZ9q2DyGEU8rMzOTjjz++4t8bPnw4mZlXnidjxoxhzpw5V/x7taHKcFdGx8/nwC6t9buVbBNm3Q6lVDfrftPtWWi5g8GQNyH/NKx6p0YOIYRwTJWFe0lJyWV/b+HChdSvX7+myjJFdUbL9AbuB3YopbZan/sb0ARAaz0NuAN4XClVDOQDo7XWugbqNYR3gs73wPpP4NpHICi6xg4lhLDN6//ZSWLqxT24V6dtRACv3lz5Kb2JEydy4MABOnfujMViwc/Pj/DwcLZu3UpiYiK33norycnJFBQU8OSTTzJ27Fjg/FxXubm5DBs2jD59+rB27VoiIyP56aef8Pb2rrK2ZcuW8eyzz1JcXMy1117L1KlT8fT0ZOLEiSxYsAAPDw8GDx7MO++8w7///W9ef/113N3dCQwMZOXKlXZ7j8pUGe5a69XAZU/baq0/Aj6yV1HVMvAl2DkPlr4Gd35Vq4cWQtRNb7/9NgkJCWzdupUVK1Zw4403kpCQcG6s+BdffEGDBg3Iz8/n2muvZeTIkTRs2PCCfezbt4+ZM2fy6aefMmrUKObOnct999132eMWFBQwZswYli1bRqtWrXjggQeYOnUqDzzwAPPmzWP37t0opc51/UyaNInFixcTGRlpU3dQdTjuFaoBEdBrAvz+NvQYB427mV2REKKcy7Wwa0u3bt0uuAjogw8+YN68eQAkJyezb9++S8I9JiaGzp07A9C1a1eSkpKqPM6ePXuIiYmhVatWADz44INMmTKF8ePH4+XlxSOPPMKNN97ITTcZlwL17t2bMWPGMGrUKG6//XZ7/KmXcOy5ZXpPAL8wWPw3qMFeICGEY/L19T13f8WKFSxdupQ//viDbdu20aVLlwqnSfD09Dx3393dneLi4iqPU1kvtIeHBxs2bGDkyJHMnz+foUOHAjBt2jQmT55McnIynTt3Jj3d/qcoHTvc6/ka3TMpG2HnJYN4hBAuxt/fn5ycnApfy8rKIigoCB8fH3bv3s26devsdtzWrVuTlJTE/v37Afj222/p168fubm5ZGVlMXz4cN5//322bjVOWx44cIDu3bszadIkgoODSU5OtlstZRy3W6ZM2YnVpa9B7I1g8TK7IiGESRo2bEjv3r1p37493t7eNGrU6NxrQ4cOZdq0aXTs2JHY2Fh69Ohht+N6eXnx5Zdfcuedd547ofrYY4+RkZHBiBEjKCgoQGvNe++9B8Bzzz3Hvn370FozaNAgOnXqZLdayqiaHNRyOXFxcdpuKzEdXAHfjIDrX4c+T9lnn0KIK7Zr1y7atGljdhlOo6L3Uym1SWsdV9XvOna3TJlm/aHlEFj1T8g7ZXY1QghhOucId4DBb0BhHqx42+xKhBBO5oknnqBz584X3L78sm5PgeL4fe5lQmIh7iGI/wK6/dl4LIQQdjBlyhSzS7hiztNyB+j/gjGCZskrZlcihBCmcq5w9w2Gvn+FvYuMk6xCCOGinCvcAbo/DoFNYPFLUHr5yYKEEMJZOV+4W7zg+lfhxA7YNtPsaoQQwhTOF+4A7UdCZBwss46gEUKISvj5+VX6WlJSEu3bt6/FauzHOcNdKRjyFuQeh7Ufml2NEELUOucZCnmxJt2h7a2w5l9wzYMQEG52RUK4ll8mwvEd9t1nWAcYdvlrWZ5//nmaNm3KuHHjAHjttddQSrFy5UpOnz5NUVERkydPZsSIEVd06IKCAh5//HHi4+Px8PDg3XffZcCAAezcuZOHHnqIwsJCSktLmTt3LhEREYwaNYqUlBRKSkp4+eWXueuuu2z+s23hnC33Mte/BqXF8NtksysRQtSS0aNHM3v27HOPf/jhBx566CHmzZvH5s2bWb58Oc8880ylMzlWpmys+44dO5g5cyYPPvggBQUFTJs2jSeffJKtW7cSHx9PVFQUixYtIiIigm3btpGQkHBuNsja5Lwtd4AGMdD9UVj7kfEzvKPZFQnhOqpoYdeULl26cPLkSVJTU0lLSyMoKIjw8HCefvppVq5ciZubG0ePHuXEiROEhYVVe7+rV6/mL3/5C2DMAtm0aVP27t1Lz549efPNN0lJSeH222+nZcuWdOjQgWeffZbnn3+em266ib59+9bUn1sp5265A/R9FryD4NcXZc53IVzEHXfcwZw5c5g9ezajR49mxowZpKWlsWnTJrZu3UqjRo0qnMv9cipr6d9zzz0sWLAAb29vhgwZwm+//UarVq3YtGkTHTp04IUXXmDSpEn2+LOuiPOHu3d96D8RDq2EvYvNrkYIUQtGjx7NrFmzmDNnDnfccQdZWVmEhoZisVhYvnw5hw8fvuJ9XnfddcyYMQOAvXv3cuTIEWJjYzl48CDNmjVjwoQJ3HLLLWzfvp3U1FR8fHy47777ePbZZ9m8ebO9/8QqOXe3TJm4P8GG6bDkZWgxCNwtZlckhKhB7dq1Iycnh8jISMLDw7n33nu5+eabiYuLo3PnzrRu3fqK9zlu3Dgee+wxOnTogIeHB1999RWenp7Mnj2b7777DovFQlhYGK+88gobN27kueeew83NDYvFwtSpU2vgr7w855jPvTp2L4RZd8Pwd4yJxYQQdifzuduXzOdeHbHDILovrPg7FGSZXY0QQtQo1wl3pWDwZDiTYSzqIYQQVjt27Lhkvvbu3bubXdZVcY0+9zIRnaHT3bBuqtEPHxRtdkVCOB2tNUops8u4Ih06dDi3eHVdcbVd5q7Tci8z6GVQ7rD0dbMrEcLpeHl5kZ6eftXB5Oq01qSnp+Pl5WXzPhyy5X5VLYOACOg9AX7/X+jxODTuZt/ihHBhUVFRpKSkkJaWZnYpDs/Ly4uoqCibf9/hwn3dwXTe/HkX3z7cjfo+9WzbSa8JsOkrWPw3eHiJ0R8vhLhqFouFmJgYs8sQOGC3TKC3hcRj2fxj8R7bd+LpBwNfgpSNsHOe/YoTQog6wuHCvU14AGN6RTNzwxG2HDlt+4463wuN2sPS16D4rN3qE0KIusDhwh3gqetbEurvyUvzEygptfHEjZu7MTQy8zCs/8S+BQohhMkcMtz9vSy8fFNbdqZm8926K58j4pzmA6DlYFj5DuSl269AIYQwmUOGO8CNHcLp2zKYdxbv4WTOlc3udoEb3oDCXPjdnOlJhRCiJlQZ7kqpxkqp5UqpXUqpnUqpJyvYRimlPlBK7VdKbVdKXVMz5V5wTF6/pR1ni0t56+ddtu8otDV0HQMbP4e0vXarTwghzFSdlnsx8IzWug3QA3hCKdX2om2GAS2tt7FArUyB1izEj8f6NWP+1lTWHjhl+476vwAWH1jyiv2KE0IIE1UZ7lrrY1rrzdb7OcAuIPKizUYA32jDOqC+UqpWFi0dN6AFjRt48/L8BAqLS23biV8IXPcM7P3FmPddCCEc3BX1uSulooEuwPqLXooEkss9TuHSD4Aa4WVxZ9It7TmQlsdnqw/avqPuj0NgE+PCptIS+xUohBAmqHa4K6X8gLnAU1rr7ItfruBXLhmjqJQaq5SKV0rF2/Py5AGtQxnSrhEfLNtHyukztu3E4gXXv2qs1r5tlt1qE0IIM1Qr3JVSFoxgn6G1/rGCTVKAxuUeRwGpF2+ktZ6utY7TWseFhITYUm+lXr25HW5K8fp/Em3fSfuRENkVfnsDCvPsV5wQQtSy6oyWUcDnwC6t9buVbLYAeMA6aqYHkKW1PmbHOqsUUd+bJwe1ZEniCZYmnrBtJ0rBkLcg5xis/ci+BQohRC2qTsu9N3A/MFAptdV6G66Uekwp9Zh1m4XAQWA/8CkwrmbKvbw/9YmhZagfr/1nJ/mFNvabN+kBbUfAmvchu1Y/n4QQwm6qM1pmtdZaaa07aq07W28LtdbTtNbTrNtorfUTWuvmWusOWutaXBz1PIu7G5NvbU/K6XymLN9v+46ufw1KimD5ZHuVJoQQtcphr1CtTPdmDbn9mkg+WXmAA2m5tu2kQTPo/ihsmWGcYBVCCAfjdOEO8MKwNnhb3HnlpwTbV4S57lnwrg+LXwRZVUYI4WCcMtxD/D15bmhr1uxP5z/bbew39w6CfhPh0O+w71f7FiiEEDXMKcMd4J5uTegYFcgb/00ku6DItp1c+zA0bAG/vgwlxfYtUAghapDThru7m2Lyre05lXuW95bYOCGYuwVumASn9sDmr+xanxBC1CSnDXeAjlH1ua97U75em8TO1CzbdhI7HJr2geVvQYGN+xBCiFrm1OEO8OzgWBr41uOl+QmU2rJqk1Iw5E04kwGrKruGSwgh6hanD/dAHwt/G96GLUcy+SE+uepfqEhEZ+g0GtZNhdNXsfKTEELUEqcPd4DbukTSLaYBby/aTUZeoW07GfgyKDdY9rp9ixNCiBrgEuGulHFyNbegmLd/sXHVpsBI6PUXSJgLKaZcgCuEENXmEuEO0KqRPw/3jeGH+BTikzJs20nvJ8GvkTHnu1zYJISow1wm3AEmDGxJRKAXL81PoLjEhlWbPP1gwIuQvB4S59u/QCGEsBOXCndfTw9eubkdu4/n8NXaJNt20uU+CG0HS16F4rN2rU8IIezFpcIdYEi7RgyIDeG9JXs5nlVw5Ttwc4chkyHzMGyYbv8ChRDCDlwu3JVSvH5Le4pLNW/8bOOqTc0HQosbjGkJpvaBX56HxAWQl27fYoUQwkYeZhdghiYNfXhiQAveXbKXu+LSuK6VDUv+3T4dNn4GSath09ewfprxfGhbaNobonsbV7b62Xc5QSGEqA5l85S4VykuLk7Hx5s3pLCgqIRh/1qF1ppFT12Hl8Xd9p0VF0LqZiPoD6+BI+uhyLoGa3CsNeh7Q3Qf8A+zzx8ghHBJSqlNWuu4Krdz1XAHWLk3jQe+2MBfb2jFhEEt7bfjkiJI3QqHV0PSGjiyDgpzjNcaNDdCPrqPEfiBkfY7rhDC6Um4V9MT329mSeIJljx9HU0b+tbMQUqK4fj28y37w3/AWeskZEHR1qDvY7Tw6zepmRqEEE5Bwr2ajmcVMOifK+gW04AvxlyLUqrmD1paAicSjLBPWmMEfkGm8VpgEyPky1r2QdHG5GVCCEH1w90lT6iWFxboxdM3tGLyz7tYvPMEQ9vXQp+4mzuEdzJuPZ+A0lI4mWht2a82Vn7aNtPYNiDyfH99dB9jfVcJeyFEFVy+5Q5QXFLKTR+uJju/iCV/7Yevp8mfeaWlxgIhZd04SashL814zS+s3AnavhDcUsJeCBci3TJXKD4pgzum/cGj/ZrxwrA2ZpdzIa3h1L7zJ2gPr4Ec69qwvqHQ/nYY9ArUq6FzBkKIOkO6Za5QXHQDRsVF8fmqQ4y8JopWjfzNLuk8pSCklXGL+5MR9hkHjRb9wRWw/hPYvwxGfmbMPS+EcHkud4Xq5Uwc1gY/Lw9emp+AWd9oqkUpaNgcuj4Id34JDy6Awjz47HpY84HRrSOEcGkS7uU08K3H80Nbs+FQBvO2HDW7nOqLuQ4eXwOxQ2HJy/DdbZB9zOyqhBAmknC/yF1xjencuD5vLdxF1pkis8upPp8GMOpbuPkDSN4AU3vB7p/NrkoIYRIJ94u4uRmrNmXkFfLOr3vMLufKKGV01Ty6Euo3hln3wH+fhsIzZlcmhKhlEu4VaB8ZyAM9o/lu/WG2p2SaXc6VC24JDy+FXhMg/guY3h+ObTe7KiFELZJwr8RfB7ci2M+Tl+YnUFJah0+uVsajHgx+A+6fDwVZ8NkgWPuRnGwVwkVIuFciwMvCSze2YXtKFt9vOGJ2ObZrPgAeX2udf/5FmDESco6bXZUQooZJuF/GLZ0i6NW8If9YtJu0HAdeUs+3IYyeATe9Z0xaNrUX7FlkdlVCiBpUZbgrpb5QSp1USiVU8np/pVSWUmqr9faK/cs0h1KKSSPaU1BUwt9/2WV2OVdHKeMCqEd/h4AImHkX/PwMFOWbXZkQogZUp+X+FTC0im1Waa07W2+Trr6suqNFqB9jr2vGj5uPsu6gEyyjFxILjyyDnuONlaSm94fjFX5uCyEcWJXhrrVeCWTUQi111vgBLYms783L8xMoKnGCE5IenjDkTbjvR8g/DZ8OhHVTjWkNhBBOwV597j2VUtuUUr8opdpVtpFSaqxSKl4pFZ+WlmanQ9c873ruvH5LO/adzOWL1YfMLsd+WgwyTrY2HwCLJsKMOyD3pNlVCSHswB7hvhloqrXuBHwIzK9sQ631dK11nNY6LiTEsRaOvr5tI65v04j3l+4jNdOJ+ql9g+HuWTD8HWMiso97wt5fza5KCHGVrjrctdbZWutc6/2FgEUpFXzVldVBr97cFo1m0n8SzS7FvpSCbn+GsSuMBby/vxMW/g8UFZhdmRDCRlcd7kqpMGVdm04p1c26Tyc483ipxg18+MvAlizaeZzlu52w+yK0jXGytfvjsOET+HQAnHCyDzIhXER1hkLOBP4AYpVSKUqph5VSjymlHrNucgeQoJTaBnwAjNZ1er7cq/Pnvs1oHuLLqwt2UlBUYnY59mfxgmFvw71zIe+UMZpm/XQ52SqEg5GVmGyw9sAp7vl0PRMGteSvN7Qyu5yak5sGP40z1nRtOQRGTAE/xzpXIkSdU1wIJWfB07YFgaq7EpNcoWqDXs2DubVzBB8v38/a/afMLqfm+IXAPT/AsH8YKz5N7QX7lppdlRCOR2s4st6YpfWfrYyhxzVMwt1Gr49oT7MQXx79bhN7T+SYXU7NUQq6Pwpjlxsja2aMhEUv1L2TrVobY/bT9kCxA08VIZzLqf3w25vwQWf4YjBsnQktrjcWuK9h0i1zFY5m5nPblDV4uCnmPdGbRgFeZpdUs4ryYcmrxsnWRu1h5OcQ2rrmj1taCnknITvVuOUcg+yj5x+XPVdknbfe4muM3Y8dDi0HS1eSqF25abDzR9g+G45uAuUGMf2g413Q5iabu2PKVLdbRsL9KiUczWLUJ38QE+zL7Ed74ufpAmuO710M88dBYS4MngzXPmK08G1RXGgN61TIKQvrcuGdc8y4lRZf+HtuHuAfYcyTExAOAZHgHw4+DSFlgzExWk4qoCDqWmMJwlbDjBFBttYqRGUKz8CehUag718GugTCOhiB3v4O49+onUi416Lle07yyNfx9GkRzOcPxuHh7gK9XTknjJOt+5caoTniI6PbpryzuReFdvmWtvVnXgVXKlt8rKEdcT60zz22PucTDG6XeZ+1huPbYc8vxu3YVuP5+k2h1VCIHWZ8NfaoZ7/3RLiW0hJIWgXbZsOuBUZjJyAKOt4JHUZBo7Y1clgJ91o2c8MRXvhxB3d3a8xbt3VAuULrsLQU1k+Dpa+Cd5AxZ3z51vfZrEt/xzvoosCOtLa8I863xL0C7d+6zj4GexcZt4MroLgAPAOg+UAj6FsONtahFaIqxxNg+yzYMcf4VukZAG1HGK30pr0v3+iwAwl3E/zf4t1MWX6A54bE8sSAFmaXU3uO74CfxhuLgFzQwr6o5e0fDvV8zK7W+Ap9cAXs/cXoYso9YfSLNu5xvvsmuKV034jzso7Cjn/D9h/g5E6jW7DlYOg4yvgmaPGutVIk3E2gteap2Vv5aWsq/xrdmRGdI80uSVSltBSObTH66Pf8Aid2GM83aGaEfOxQaNIT3C3m1ilqX0G20d2ybZYx7xIaoroZgd7udmMRHBNIuJvkbHEJD3y+gS1HMvnm4W70aGbOPwBho8zk8903h1ZCSaHRTdTiBqP7psUgo2tJOKeSIuOE6PZZxod9cYHxQd/xLiPUGzQzu0IJdzNlnSli5LS1nMwu4MdxvWgRenVDn4RJzubAgeXWsF8MZ06BcoemvYygbzUUGjY3u0pxtbQ2hixum2UMYTyTboy6aj/SCPXIrnWqi07C3WTJGWe47eO1eHq4Me+JXoT6O/kYeGdXWmIEQNnomzTrsovBrc6PvonqBu4uMBTWWaQfsPajz4aMg+DhZVwb0fEu4xtaHe2Kk3CvA3akGGPgW4T6MWtsD3xdYQy8qzidZPTT7/0FktZAaZHRXdNysBH0zQeBV4DZVYqL5aVbLzD6wbgeAgUxfa0XGN1sdMHVcRLudcSyXSf48zfxDIgN5ZP7u7rGGHhXU5AFB34zWvT7fjWmQXCzQOvh0Pk+Y7iltOjNUVJsXOOQtMo4h3JopXFBXGhbI9A73AmBjjXwQcK9Dvlu3WFemp/AfT2a8MaI9q4xBt5VlRQbLcLEBbDjB6P/1j8cOo02gj7YhYbImqG0xLh47dAqI9AP/wGF1rmfQlpDyxug42gIa29unVdBwr2O+fsvu/jk94O8MKw1j/aTk3AuobjQOBm75TvYvwR0qTGWvst90O7Wq55jRGAMZT2RYAxVTFoFh9cY36QAGraE6D5Gt0t0X/ALNbdWO5Fwr2NKSzUTZm3hv9uP8eHdXbi5U4TZJYnalH3MGF63ZQak7zMmN2t3qxH0TXrWqdEYdZrWcHLX+W6Ww2uMbjCAoBhrkF9nhLod53OpSyTc66CCImMM/NbkTL57pDvdYuRyd5ejNSRvgK3fQcKPxnwkDZpB53uh090O1/9b47SGU/sgaaW1q2W1MSQVILDJ+VZ5TF8IjDK31loi4V5HZZ4p5Papa0nPLeTHcb1oHuJndknCLIV5Rt/8lu/g8GpjCoTmA42gb30jeHiaXWHt09oYlnho5fmultwTxmsBkUaQl3W1BEWbWqpZJNzrsCPpZ7h96hq867nz4+O9CfF3wf/E4kIZB2Hr98Yt+6gxrLLDKOhyL4R3Mru6mnU66fwJ0EOrrFM1A36NzrfKo/sa33Ck+0rCva7blpzJXdP/ILaRPzPH9sCnngyVExijPQ6uMFrzu3821toM62CMtOk4yjlmrsxMPt8qP7QKso4Yz/sElzsBep1M3lYJCXcHsCTxBI9+G8/A1o345P6uuLvJP2RRzpkMSJgLW76FY9vAvZ5xgVSX+43uGzd3syus2tlcyEo2Zg49tNII9NNJxmveQUaYl50AlYVUqkXC3UF880cSr/y0kwd7NuW1W9rJGHhRseM7jJE222dDfoZ17Pzdxmgbs+a30RoKMiHziNEaz0q23j9ivZ9s1FrGMxCie5/vagltV+NznzsjCXcH8ubPiXy66hAv3diGR/qaP+ucqMOKC40pD7bMOD92vklPI+Tb3gqedjxBr7WxUlZmMmQePh/Y5cO78KLF4S0+ENgY6je2/mxi3Bq2MLqXHOHbRh0n4e5ASks142duZuGO43x87zUM7+Cc43OFnZ0bO/8dpO+3jp2/zTgJW52x86UlxkpC51rdhy9sgWelGFPelucZaA3s8uFd7r5PQ+laqWES7g6moKiEez9bz46jWcz8c3e6NnWCE2eidpSNnd/yLeycZx073xw632PMWHkmvYJW9xFjVM7FC4/7BBthXb/JhS3vsta4A0ys5ewk3B1QRl4hI6euJfNMIXMf70UzGQMvrtTZXGP1oC3fGVdvXkAZffWXtLrLAjyqbiyDKC5Lwt1BHU7P4/aP1+Lr6cG8cb1o6Cdj4IWN0g9ASjz4hxkhHhAFHvXMrkpcpeqGu5yqrmOaNvTl0wfjOJFdwMNfx5NfWGJ2ScJRNWwOne6CZv2MC4Ak2F2KhHsddE2TIP41ugvbUjJ5avYWSkrN+XYlhHBcEu511ND2Ybx8Y1sW7zzBmz/vMrscIYSDkWve67A/9Ykh5XQ+X6w5RFSQN3/qE2N2SUIIB1Fly10p9YVS6qRSKqGS15VS6gOl1H6l1Hal1DX2L9N1vXhjG4a0a8QbPyeyKOG42eUIIRxEdbplvgKGXub1YUBL620sMPXqyxJl3N0U79/Vhc6N6/PkrC1sPnLa7JKEEA6gynDXWq8EMi6zyQjgG21YB9RXSskllnbkXc+dzx6IIyzQi0e+jifpVJ7ZJQkh6jh7nFCNBJLLPU6xPifsqKGfJ1891A2tNQ99tZGMvEKzSxJC1GH2CPeKJpKocOyeUmqsUipeKRWflpZmh0O7lphgXz57MI6jmfn8+Zt4CopkDLwQomL2CPcUoHG5x1FAakUbaq2na63jtNZxISEhdji06+natAHv39WZzUdO89cftlIqY+CFEBWwR7gvAB6wjprpAWRprY/ZYb+iEsM7hPPi8DYs3HGcv/8iY+CFEJeqcpy7Umom0B8IVkqlAK8CFgCt9TRgITAc2A+cAR6qqWLFeQ9bx8B/uuoQjQK8ZB54IcQFqgx3rfXdVbyugSfsVpHMOVWBAAARe0lEQVSoFqUUL9/UluNZBUz+eRdHM/N5cXgbPNzlomMhhEw/4NDc3RQf3dOFP/WO4cs1STz01UayzhSZXZYQog6QcHdwHu5uvHJzW/4xsiPrDqZz28drOJCWa3ZZQgiTSbg7iVHXNub7P/cgK7+IW6es4fe9MtRUCFcm4e5Ero1uwE/jexMV5MNDX27g89WHMGsxFiGEuSTcnUxUkA9zHuvJDW0b8cZ/E3l+7nbOFsvFTkK4Ggl3J+Tr6cHUe7syYWALfohP4d5P13Mq96zZZQkhapGEu5Nyc1P8dXAsH93ThYTULEZ8tIbE1GyzyxJC1BIJdyd3U8cI/v1oL0pKNSOnrmVRglw8LIQrkHB3AR2iAlkwvjexYf489t1mPli2T060CuHkJNxdRGiAF7PG9uD2LpG8u2Qv42duIb9QTrQK4axkDVUX4mVx55+jOhEb5s/bi3ZzOD2P6ffHEVHf2+zShBB2Ji13F6OU4tF+zfn8wTiSTp3hlo/WyNJ9QjghCXcXNbB1I+aN64WvpzujP1nH3E0pZpckhLAjCXcX1rKRP/PH9aZr0yCe+fc23lq4ixJZ/EMIpyDh7uKCfOvxzcPduL9HU6avPMgjX28kp0BmlhTC0Um4Cyzubrxxa3sm39qeVftOcdvHa0k6lWd2WUKIqyDhLs65r0dTvnm4G6dyzzJiyhrW7j9ldklCCBtJuIsL9GoezE9P9CbU35P7v9jAN38kyQVPQjggCXdxiaYNfflxXC/6twrhlZ928uL8BIpKSs0uSwhxBSTcRYX8vSxMfyCOx/o15/v1R7jvs/Vk5BWaXZYQopok3EWl3N0UE4e15r27OrElOZMRU1az53iO2WUJIapBwl1U6bYuUcwe24OColJu/3gNSxJPmF2SEKIKEu6iWro0CWLB+N40C/Fj7LfxfLxiv5xoFaIOk3AX1RYe6M2/H+vJTR0j+MeiPTw1eysFRTKzpBB1kcwKKa6Il8WdD0Z3JraRH+/8upekU3lMfyCORgFeZpcmhChHWu7iiimlGD+wJZ/c35V9J3O55aPVbEvONLssIUQ5Eu7CZkPahTH38V54uLkx6pM/+G7dYZl4TIg6QsJdXJU24QEsGG/MLPnS/ARu/nA16w+mm12WEC5Pwl1ctYZ+nsx4pDsf3t2FzDOF3DV9HU98v5mjmflmlyaEy5JwF3ahlOLmThEse6Y/Tw5qydLEEwx8ZwXvLdkra7UKYQIJd2FX3vXcefqGVvz2bH9uaNuIfy3bx8B/rmDBtlQZFy9ELZJwFzUisr43H91zDT882pMGvvWYMHMLd077gx0pWWaXJoRLqFa4K6WGKqX2KKX2K6UmVvD6GKVUmlJqq/X2iP1LFY6oW0wDFozvw9u3d+DQqTxumbKa5+dsJy3nrNmlCeHUqryISSnlDkwBbgBSgI1KqQVa68SLNp2ttR5fAzUKB+fuphjdrQnDO4bz4bJ9fLkmiYU7jvGXQS0Y0yuGeh7yBVIIe6vO/6puwH6t9UGtdSEwCxhRs2UJZxTgZeHFG9uy+OnruDamAW8t3M2Q91fy2+4T0h8vhJ1VJ9wjgeRyj1Osz11spFJqu1JqjlKqsV2qE06peYgfX4y5li8fuhal4E9fxTPmy43sPynTCQthL9UJd1XBcxc3s/4DRGutOwJLga8r3JFSY5VS8Uqp+LS0tCurVDidAbGhLH7qOl66sQ2bj5xm6PurmPSfRLLyi8wuTQiHV51wTwHKt8SjgNTyG2it07XWZWfIPgW6VrQjrfV0rXWc1jouJCTElnqFk7G4u/FI32Ysf7Y/d8Y15su1hxjwzgpmrJepDIS4GtUJ941AS6VUjFKqHjAaWFB+A6VUeLmHtwC77FeicAXBfp78/fYO/PcvfWgR6seL8xK46cPVrJOpDISwSZXhrrUuBsYDizFC+wet9U6l1CSl1C3WzSYopXYqpbYBE4AxNVWwcG7tIgKZPbYHU+65huz8IkZPX8cTMzaTnHHG7NKqpLXmeFYBy3ad4Nt1hzmVK8M9hXmUWaMU4uLidHx8vCnHFo6hoKiE6SsPWld9gkeva8Zj/ZvjU8/8ZQhKSjWHTuWyMzWbxNRsEo9lszM1+4JFxP09PRg/sAVjekfj6eFuYrXCmSilNmmt46rcTsJd1HWpmfn876Ld/LQ1lbAAL14Y3ppbOkWgVEXn+u0vv7CE3ceN8E48ZoT57uPZFBSVAlDP3Y3YMH/ahgfQNiKAdhEBeFnceXfJXn7bfZImDXz42/DWDGkXVms1C+cl4S6cTnxSBq//J5EdR7Po2jSIV29uS8eo+nY9Rnru2XOt8LIW+cG0XMrO7QZ4eVgDPJC24QG0iwygeYgfFveKezhX7k1j8s+J7D2RS/eYBrx8U1vaRwbatWbhWiTchVMqLdXM2ZTCPxbvJj2vkDuuieK5obGE+l/ZMn9aa45knLmgSyUxNZvj2QXntoms702bcKMl3jYigLbhAUQFeV9x67u4pJRZG5N5d8leTp+x1jwkllBZmlDYQMJdOLWcgiI++m0/X6w5hKeHO+MHtuChSvq2C4tL2Xsi51yXSmJqNruOZZNzthgwpkdoHuJ7vjUeEUCb8ACCfOvZteas/CKmLN/Pl2sOYXF3Y1z/5jzStxleFumPF9Un4S5cwqFTebz5cyJLd50kuqEPE4e1IcjHcq5/fGdqNvtP5lBUYvw797a40ybc3whya2s8Nsy/VgM26VQef/9lF4t3niCyvjf/MzS2Vs8hCMcm4S5cyu9703jjv4nsP5l77rlgv3q0LdcabxsRQHRDX9zd6kaI/nEgnck/J7IzNZsuTerz8k1tuaZJkNlliTpOwl24nKKSUn7deQIfT3fahQc4RJ92Salm7uYU/m/xHtJyzjKicwTPD21NRH1vs0sTdZSEuxAOJPdsMdNWHODTVQcBY0z/o/2a4+tp/ph+UbdUN9xlIm0h6gA/Tw+eHRLLsmf6MbhdGB/8tp8B76xgzqYUSmWOHWEDCXch6pCoIB8+vLsLcx/vRUR9b5799zZGTFnDhkMZZpcmHIyEuxB1UNemQfz4eC/ev6szp3LPMuqTPxg3Y5NDzLEj6gbp0BOijnJzU9zaJZIh7cL4dNVBpq44wNLEkzzUJ5rxA1rg72Uxu0RRh0nLXYg6zrueOxMGtWT5s/25uVMEn/x+kAHvrOD79UdkzntRKQl3IRxEWKAX/xzViQXjexMT7Mvf5u3gxg9WsWb/KbNLE3WQhLsQDqZjVH1+eLQnH997DXmFxdz72Xoe+XojB9Nyq/5l4TIk3IVwQEophncIZ8nT/Zg4rDXrDmYw+L2Vxhq0Z2QNWiHhLoRD87K481i/5ufWoP1q7SH6vbOcr9Ycoqik1OzyhInkClUhnMiuY9lM/jmRNfvTaR7iyzODY+kQGUh4oBcelcw5LxyLTD8ghIvSWrN010neWriLQ6fyAGNa48j63jRu4E2TBj5EBfnQpIFxa9zAhyAfi8xK6SCqG+4yzl0IJ6OU4oa2jejXKoT4wxkkZ5zhSMYZkjPyOZJxhl93niC93FqvYEx/EBXkfS7sjZ/nPwhkznnHI+EuhJOq5+FGr+bB0PzS1/LOFpN8+nzgJ1tvSel5rNyXdm592DKh/p7ngr9xAx8aWz8ImjT0oZG/F251ZBplcZ6EuxAuyNfTg9ZhAbQOC7jkNa01ablnSc7IPxf6RzLOkHz6DBsOZfDT1qOUv3aqnrsbUUHeRDXwoUkDbxoH+VzwQRDoLVfSmkHCXQhxAaUUof5ehPp70bXppYuHFBaXkpqZfy7wj2ScIcX6DWB7SiaZFw3FDPS2EBXkTXigF+GB3oQFehFR34uwAG8i6nvRKMBLun1qgIS7EOKK1PNwIzrYl+hg3wpfzy4ourDFn5FPyukzpJzOZ2PSabLyLx2H39C3HmHW8I+o72V8AJR9EAR60yjQs8L1cUXlJNyFEHYV4GWhXUQg7SICK3z9TGExx7IKOJ5VQGpmvvEzq4DjWcaHwMakjAo/AIL9zn8AhF/w07gvHwAXknAXQtQqn3oeNA/xo3mIX6Xb5J0t5nh2AccyCziWlc+xrALrzTgPsP5gOtkFxZf8XrBfvfNdP4FehJV9EwjwIqK+N6EBrvMBIOEuhKhzfD2r9wFQFvjHsowPguPZ+aRmFnAk/QzrDqaTU8EHQKC3hVB/T0L8Pcv99LrkcYC3h0OP/ZdwF0I4JF9PD1qE+tEitPIPgNyzxRwvF/4nsgtIyz3LyeyzpOWeZdOR05zMPsvZ4kunaqjn4UaIXxUfAgGeBPt5YqmDV/9KuAshnJafpwctQv1pEepf6TZaa3LOFpOWcz70T1o/BNKsjw+nnyH+8GkyLrr4q0wD33qE+BlhH+LnSYj1Z2iA1/nn/T3x96y9bwMS7kIIl6aUIsDLQoCX5bLdQGAMA03Ps34I5JzlZE7Zz4Jzjw+m5ZGWc5bCCiZu87K4EeLvyQM9ovnzdc1q6k8CJNyFEKLa6nm4WUfpeF92O6012fnFF4R++Q+B0ADPGq9Vwl0IIexMKUWgj4VAHwstG1XeJVSTqnUWQCk1VCm1Rym1Xyk1sYLXPZVSs62vr1dKRdu7UCGEENVXZbgrpdyBKcAwoC1wt1Kq7UWbPQyc1lq3AN4D/tfehQohhKi+6rTcuwH7tdYHtdaFwCxgxEXbjAC+tt6fAwxSjjxAVAghHFx1wj0SSC73OMX6XIXbaK2LgSyg4cU7UkqNVUrFK6Xi09LSbKtYCCFElaoT7hW1wC9evqk626C1nq61jtNax4WEhFSnPiGEEDaoTrinAI3LPY4CUivbRinlAQQCGfYoUAghxJWrTrhvBFoqpWKUUvWA0cCCi7ZZADxovX8H8Js2a3FWIYQQVY9z11oXK6XGA4sBd+ALrfVOpdQkIF5rvQD4HPhWKbUfo8U+uiaLFkIIcXnKrAa2UioNOGzKwe0nGDhldhF1iLwfF5L34zx5Ly50Ne9HU611lSctTQt3Z6CUitdax5ldR10h78eF5P04T96LC9XG+1H35qkUQghx1STchRDCCUm4X53pZhdQx8j7cSF5P86T9+JCNf5+SJ+7EEI4IWm5CyGEE5Jwt4FSqrFSarlSapdSaqdS6kmzazKbUspdKbVFKfVfs2sxm1KqvlJqjlJqt/XfSE+zazKTUupp6/+TBKXUTKWUl9k11Sal1BdKqZNKqYRyzzVQSi1RSu2z/gyy93El3G1TDDyjtW4D9ACeqGAaZFfzJLDL7CLqiH8Bi7TWrYFOuPD7opSKBCYAcVrr9hgXQrraRY5fAUMvem4isExr3RJYZn1sVxLuNtBaH9Nab7bez8H4z3vxTJkuQykVBdwIfGZ2LWZTSgUA12FctY3WulBrnWluVabzALyt8075cOncVE5Na72SS+faKj9N+tfArfY+roT7VbKuOtUFWG9uJaZ6H/gf4NIVgV1PMyAN+NLaTfWZUsrX7KLMorU+CrwDHAGOAVla61/NrapOaKS1PgZGYxEItfcBJNyvglLKD5gLPKW1zja7HjMopW4CTmqtN5ldSx3hAVwDTNVadwHyqIGv3I7C2pc8AogBIgBfpdR95lblGiTcbaSUsmAE+wyt9Y9m12Oi3sAtSqkkjFW6BiqlvjO3JFOlACla67JvcnMwwt5VXQ8c0lqnaa2LgB+BXibXVBecUEqFA1h/nrT3ASTcbWBdQvBzYJfW+l2z6zGT1voFrXWU1joa40TZb1prl22Zaa2PA8lKqVjrU4OARBNLMtsRoIdSysf6/2YQLnyCuZzy06Q/CPxk7wNUOeWvqFBv4H5gh1Jqq/W5v2mtF5pYk6g7/gLMsK5/cBB4yOR6TKO1Xq+UmgNsxhhltgUXu1pVKTUT6A8EK6VSgFeBt4EflFIPY3wA3mn348oVqkII4XykW0YIIZyQhLsQQjghCXchhHBCEu5CCOGEJNyFEMIJSbgLIYQTknAXQggnJOEuhBBO6P8B+ahUWdBMQPQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, len(dnn.train_loss)+1), dnn.train_loss, label=\"train_loss\")\n",
    "plt.plot(np.arange(1, len(dnn.train_loss)+1), dnn.test_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
